{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lyhue1991/zztest/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyIh9MLyl4vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip cifar2_datasets.zip -d cifar2_datasets/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt_eVeU4ot_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "98d22845-75e0-4d47-8fa7-583ec3f2d71e"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "x = np.random.randn(5,10)\n",
        "y = np.random.randn(10,5)\n",
        "\n",
        "np.dot(x,y)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.98157341e+00, -2.16382063e+00, -1.43924155e+00,\n",
              "        -2.64058621e-03,  2.18913606e+00],\n",
              "       [-8.11214338e-01,  8.21194016e-01, -1.36981812e+00,\n",
              "         2.14662219e+00,  2.84796699e+00],\n",
              "       [-2.99426030e+00, -3.30501308e+00, -6.52658336e-01,\n",
              "         3.29338036e+00, -1.21042758e+00],\n",
              "       [-3.18335273e+00,  2.23178897e+00,  4.41138405e+00,\n",
              "         2.08540855e-02, -2.31003764e+00],\n",
              "       [-4.29531729e+00, -6.06604659e+00,  9.79018058e-01,\n",
              "         5.80929080e+00,  3.38395817e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXE3dbA8xib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QfGFeSpc_s_",
        "colab_type": "code",
        "outputId": "32fd4878-99c3-493c-ae71-2330cdaa0fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "#%%time\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "# Creates a graph.\n",
        "with tf.device('/cpu:0'):\n",
        "    a = tf.random.normal((50000,500),mean= 0,stddev= 1,dtype = tf.float32)\n",
        "\n",
        "    b = tf.random.normal((500,10000),mean= 0,stddev= 1,dtype = tf.float32)\n",
        "    c = tf.matmul(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(c))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1.6007755   21.776764   -25.635695   ... -40.673515   -19.407751\n",
            "   32.66248   ]\n",
            " [ 22.016724    40.48591     27.369627   ... -17.702246     0.61500645\n",
            "    8.474966  ]\n",
            " [-17.809708    16.603428    36.90661    ...   5.6446877   -9.450474\n",
            "   -1.7592788 ]\n",
            " ...\n",
            " [  7.899481    -3.9051094    9.660174   ... -19.634933   -34.219685\n",
            "   -0.19893456]\n",
            " [-12.392786    -9.47736     31.762444   ...  -2.489131    29.587263\n",
            "  -24.447609  ]\n",
            " [-17.420372     4.361906   -13.823677   ... -11.278049    11.641185\n",
            "  -21.767544  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah5lIlquMCN_",
        "colab_type": "code",
        "outputId": "a4fa4013-6a34-4e48-fdbe-4b87b097481f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2761
        }
      },
      "source": [
        "#设置运行时候的参数\n",
        "# Creates a graph.\n",
        "import tensorflow as tf \n",
        "\n",
        "with tf.Graph().as_default() as g:\n",
        "    \n",
        "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "    c = tf.matmul(a, b)\n",
        "\n",
        "with tf.Session(graph = g) as sess:\n",
        "    options = tf.RunOptions(output_partition_graphs=True)\n",
        "    metadata = tf.RunMetadata()\n",
        "\n",
        "    sess.run(c,options=options,run_metadata=metadata)\n",
        "    print(metadata.partition_graphs)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 定义计算图\n",
        "tf.reset_default_graph()\n",
        "\n",
        "a = tf.constant(1.0,name = 'a') ### 常量\n",
        "b = tf.placeholder(dtype = tf.float32,name = 'b') ### 占位符\n",
        "c = tf.placeholder(dtype = tf.float32,name = 'c')\n",
        "x = tf.Variable(0.1,name =  'x',trainable=True) ### 变量\n",
        "\n",
        "y = a*x**2 + b*x + c\n",
        "\n",
        "# 定义梯度下降操作符\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.05).minimize(y)\n",
        "\n",
        "#init_x = x.initializer  #仅仅对x初始化\n",
        "init = tf.global_variables_initializer() #对全部变量初始化\n",
        "\n",
        "# 执行计算图\n",
        "def run_graph(feed_dict):\n",
        "    \n",
        "    basedir = 'my_graph\\\\'\n",
        "    #注意不同的子文件夹将在run中可选\n",
        "    logdir =  basedir + 'a={},b={},c={}'.format(*feed_dict.values())  \n",
        "    with tf.Session() as sess,tf.summary.FileWriter(logdir) as writer:\n",
        "\n",
        "        #先对变量初始化\n",
        "        sess.run(init)  \n",
        "\n",
        "        #执行梯度下降100次\n",
        "        for i in range(100):\n",
        "            if i % 10 == 0: \n",
        "\n",
        "                # 配置运行时需要记录的信息。 \n",
        "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) \n",
        "                # 运行时记录运行信息的proto。 \n",
        "                run_metadata = tf.RunMetadata()\n",
        "\n",
        "                sess.run(optimizer, \n",
        "                        feed_dict= feed_dict, \n",
        "                        options=run_options, \n",
        "                        run_metadata=run_metadata) \n",
        "\n",
        "                writer.add_run_metadata(run_metadata=run_metadata, tag=(\"step%d\" % i), global_step=i) \n",
        "            else:\n",
        "                sess.run(optimizer,feed_dict = feed_dict) \n",
        "\n",
        "        print('x = ',sess.run(x,feed_dict = feed_dict)) \n",
        "        print('y = ',sess.run(y,feed_dict = feed_dict))\n",
        "\n",
        "        # 添加计算图到日志中\n",
        "        writer.add_graph(sess.graph)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[node {\n",
            "  name: \"MatMul/_0\"\n",
            "  op: \"_Send\"\n",
            "  input: \"MatMul/_0__cf__0\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"client_terminated\"\n",
            "    value {\n",
            "      b: false\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"recv_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device_incarnation\"\n",
            "    value {\n",
            "      i: 1\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_name\"\n",
            "    value {\n",
            "      s: \"edge_7_MatMul\"\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"MatMul\"\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"MatMul/_0__cf__0\"\n",
            "  op: \"Const\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"value\"\n",
            "    value {\n",
            "      tensor {\n",
            "        dtype: DT_FLOAT\n",
            "        tensor_shape {\n",
            "          dim {\n",
            "            size: 2\n",
            "          }\n",
            "          dim {\n",
            "            size: 2\n",
            "          }\n",
            "        }\n",
            "        tensor_content: \"\\000\\000\\260A\\000\\000\\340A\\000\\000DB\\000\\000\\200B\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "library {\n",
            "}\n",
            "versions {\n",
            "  producer: 27\n",
            "}\n",
            ", node {\n",
            "  name: \"MatMul/_1\"\n",
            "  op: \"_Recv\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "  attr {\n",
            "    key: \"client_terminated\"\n",
            "    value {\n",
            "      b: false\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"recv_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device_incarnation\"\n",
            "    value {\n",
            "      i: 1\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_name\"\n",
            "    value {\n",
            "      s: \"edge_7_MatMul\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_type\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"MatMul\"\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"_retval_MatMul_0_0\"\n",
            "  op: \"_Retval\"\n",
            "  input: \"MatMul/_1\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"index\"\n",
            "    value {\n",
            "      i: 0\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"_retval_MatMul_0_0\"\n",
            "  }\n",
            "}\n",
            "library {\n",
            "}\n",
            "versions {\n",
            "  producer: 27\n",
            "}\n",
            "]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIOVw9_GQU6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_graph(feed_dict = {a:1,b:-2,c:1})\n",
        "run_graph(feed_dict = {a:1,b:-4,c:4})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJKq-OqKbFYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "import tensorflow as tf\n",
        "# Creates a graph.\n",
        "with tf.device('/gpu:0'):\n",
        "    a = tf.random.normal((50000,500),mean= 0,stddev= 1,dtype = tf.float32)\n",
        "\n",
        "    b = tf.random.normal((500,10000),mean= 0,stddev= 1,dtype = tf.float32)\n",
        "    c = tf.matmul(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGerc5ApKfrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a graph.\n",
        "with tf.device('/gpu:0'):\n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "c = tf.matmul(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(c))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTg6rfg3Mw1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a graph.\n",
        "with tf.device('/device:GPU:2'):\n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "  c = tf.matmul(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(c))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps3zHA6QY7SW",
        "colab_type": "code",
        "outputId": "6777dc36-a100-4e9a-9e7c-9e1797d12a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2144
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# Creates a graph.\n",
        "c = []\n",
        "for d in ['/cpu:0', '/gpu:0']:\n",
        "    with tf.device(d):\n",
        "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
        "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
        "        c.append(tf.matmul(a, b))\n",
        "with tf.device('/cpu:0'):\n",
        "    sum = tf.add_n(c)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(sess.run(sum))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation MatMul_6: Operation was explicitly assigned to /device:cpu:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[{{node MatMul_6}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:cpu:0\"](Const_2, Const_3)]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-05d860e987c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Runs the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation MatMul_6: Operation was explicitly assigned to /device:cpu:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node MatMul_6 (defined at <ipython-input-13-dc9af82393d2>:8)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:cpu:0\"](Const_2, Const_3)]]\n\nCaused by op 'MatMul_6', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-dc9af82393d2>\", line 8, in <module>\n    c.append(tf.matmul(a, b))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2057, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4560, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation MatMul_6: Operation was explicitly assigned to /device:cpu:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[node MatMul_6 (defined at <ipython-input-13-dc9af82393d2>:8)  = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:cpu:0\"](Const_2, Const_3)]]\n"
          ]
        }
      ]
    }
  ]
}